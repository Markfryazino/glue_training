# Тестовое задание для стажировки в Tinkoff по направлению NLP
## Обучение моделей на GLUE

Ради экономии времени обучения я сравнивал лишь три маленькие модели:

1. DistilBERT (base)
1. DistilRoBERTa (base)
1. Бейзлайн: TF-IDF + логистическая регрессия

Чтобы исключить влияние случайности, я обучал все модели на каждой задаче по три раза с разными сидами.

DistilBERT и DistilRoBERTa обучались в течение двух эпох (опять же, ради экономии времени) с длиной шага оптимизации $5 \cdot 10^{-5}$ и линейным сокращением шага.

## Инструкция по запуску
Код для обучения трансформерных моделей находится в файле [transformer_glue.py](./transformer_glue.py), а для обучения логистической регрессии — в файле [logreg_glue.py](./logreg_glue.py). Скрипт [run_experiments.sh](./run_experiments.sh) содержит параметры обучения и запускает все эксперименты.

Чтобы воспроизвести результаты, нужно сделать следующее:
1. Клонировать репозиторий: `git clone https://github.com/Markfryazino/glue_training.git`
1. Установить необходимые библиотеки: `cd glue_training && pip install -r requirements.txt`
1. Запустить эксперименты: `./run_experiments.sh`

    Чтобы включить логгирование в Weights & Biases, при запуске скрипта нужно добавить параметры: `./run_experiments.sh --use_wandb --wandb_entity <YOUR_LOGIN> --wandb_project <YOUR_PROJECT>`

После завершения работы скрипта в директории появится файл `results.csv`, содержащий метрики моделей на тестовых выборках всех задач.

Если что-то сломалось или у Вас нет свободной GPU, можно воспользоваться ноутбуком в Google Colab, в котором всё точно-точно заработает: [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Markfryazino/glue_training/blob/main/demo.ipynb)

## Результаты экспериментов

Подробные метрики и графики обучения можно найти в [проекте](https://wandb.ai/broccoliman/tinkoff_qualification) Weights & Biases.

Таблица ниже показывает полученное accuracy на тестовой выборке в процентах, усреднённое по трём запускам.

|model|cola|rte|sst2|
|---|---|---|---|
|**distilbert-base-cased**|78\.56|56\.80|90\.25|
|**distilroberta-base**|82\.42|61\.13|91\.70|
|**logistic regression**|68\.55|50\.18|82\.68|

Как можно видеть, бейзлайн из логистической регрессии оказался слабее всего (оно и неудивительно), а DistilRoBERTa на всех задачах побеждает DistilBERT (что тоже неудивительно).

В целом наши результаты совпадают с результатами на GLUE, полученными авторами моделей DistilBERT и DistilRoBERTa. Так, в оригинальной [статье](https://arxiv.org/pdf/1910.01108.pdf) о DistilBERT эта модель набирает на SST-2 accuracy 91.5%, а у нас лишь на 1 процентный пункт меньше. Скорее всего, наши результаты могут быть улучшены более длительным обучением.

## Возможные улучшения

Как получить высокие результаты на GLUE, человечеству хорошо известно: достаточно взять трансформер побольше да поновее и обучать подольше. Например, можно использовать какую-нибудь версию DeBERTaV3 от Microsoft. Это можно сделать тем же кодом, который я использовал для обучения DistilBERT и DistilRoBERTa, поменяв в нём лишь название модели и, возможно, размер батча. Однако учиться такая модель будет довольно долго, так что я принял решение не проделывать эту операцию.

Вообще, честно говоря, можно было придумать тестовое задание и поинтереснее :)